# 分布式机器学习的新杀器皿  参数服务器

## 背景

* 分布式的优化AI训练已经成为一种先决定条件。但是大量数据会产生很多问题
* 访问这些巨量的参数，需要大量的网络带宽支持
* worker之间的依赖导致性能较差
* 在分布式中，容错能力是非常重要的。在很多情况下，算法都是部署到云环境中

## 发展历程

* 第一代，使用memcached键值对存储作为同步机制
* 第二代，使用bounded delay来改进模型，但是限制了worker线程模型
* 第三代， 解决这些局限性

* 通常的分布式计算系统都是，每步迭代强制同步，通常在十几个节点上，性能表现好dashi在大规模集群中，这样的每次迭代强制同步的机制会因为木桶效应变慢

* mashout基于hadoop，MIL基于spark，都是采用iterative mapreduce。采用同步迭代的通信方式，使得他们很容易因为个别机器的地性能导致全局性能的降低

* memcached作为存放参数的存储，提供了用于分布式系统不同的worker节点之间同步模型参数，而每个worker只需要保存它计算时所依赖的一小部分参数即可。

* 参数服务器是个编程框架，用于方便分布式并行程序的编写，其中重点是对大规模参数的分布式存储和协同的支持

* 参数服务器类似于mapreduce，是大规模机器学习在不断使用过程中抽象出来的框架之一。重点支持的就是参数的分布式，毕竟巨大的模型其实就是巨大的参数。

* [parameter_server](https://www.zhihu.com/question/26998075)
* 集群中的节点可以分为计算节点和参数服务节点两种。计算节点负责对分配到自己本地的训练数据计算学习，并更新对应的参数;参数服务节点采用分布式存储的方式，各自存储全局变量参数的一部分，并作为服务方接受计算节点的参数查询和更新请求

* 即计算节点负责干活和更新参数，参数服务节点则负责存储参数

### 冗余和恢复

* 类似mapreduce，每个参数在参数服务器的集群中都在多个不同节点上备份(3个挺好的)，这样当出现节点失效时，冗余的参数依旧能够保证服务的有效性。当有新的节点插入时，把原来失效节点的参数从冗余参数那边复制过来，失效节点的接班人就加入队伍了。

### 并行计算

* 这部分主要在计算节点上进行，类似mapreduce，分配任务时，会将数据拆分给每个worker节点
* 参数服务器在开始学习前，会把大规模的训练数据拆分到每个计算节点上。单个计算节点就对本地数据进行学习就可以了。学习完毕之后再把参数的更新梯度上传给对应的参数服务节点进行更新

* 计算节点(worker)和参数服务节点(parameter server)
=======
## scaling distributed machind learning， Limu

* 
